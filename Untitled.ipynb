{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>PySpark Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [1, 2, 3, 4]\n",
    "squared_my_list = list(map(lambda x: x*x, my_list))\n",
    "squared_my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_my_list = list(filter(lambda x: x%2 !=0, my_list))\n",
    "filtered_my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = list(range(0,100))\n",
    "numbersRDD = sc.parallelize(numbers)\n",
    "type(numbersRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Transformations and Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8\n",
      "27\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "numRDD = sc.parallelize(my_list)\n",
    "cubeRDD = numRDD.map(lambda x: x**3)\n",
    "numbers_all = cubeRDD.collect()\n",
    "\n",
    "[print(num) for num in numbers_all];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "(1, 6)\n",
      "(3, 6)\n"
     ]
    }
   ],
   "source": [
    "pairRDD = sc.parallelize([(1, 2), (3, 4), (1, 4), (3, 2), (4, 2)])\n",
    "pairRDD_Reduced = pairRDD.reduceByKey(lambda x, y: x+y)\n",
    "\n",
    "[print(num) for num in pairRDD_Reduced.collect()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n",
      "(3, 6)\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "pairRDD_Reduced_sorted = pairRDD_Reduced.sortByKey(ascending=True)\n",
    "[print(num) for num in pairRDD_Reduced_sorted.collect()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 2, 3: 2, 4: 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = pairRDD.countByKey()\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.defaultdict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(1, 2), (3, 2), (4, 1)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 has 2 values\n",
      "3 has 2 values\n",
      "4 has 1 values\n"
     ]
    }
   ],
   "source": [
    "[print(k, \"has\", v, \"values\") for k,v in total.items()];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession(sc)\n",
    "\n",
    "sample_list = [(\"Razi\", 39), (\"Ali\", 37), (\"Naqi\", 33)]\n",
    "sampleRDD = sc.parallelize(sample_list)\n",
    "df_sample = spark.createDataFrame(sampleRDD, schema=[\"Name\", \"Age\"])\n",
    "type(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|Razi| 39|\n",
      "| Ali| 37|\n",
      "|Naqi| 33|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people = spark.read.csv(\"people.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------------+------+-------------+\n",
      "|_c0|person_id|             name|   sex|date of birth|\n",
      "+---+---------+-----------------+------+-------------+\n",
      "|  0|      100|   Penelope Lewis|female|   1990-08-31|\n",
      "|  1|      101|    David Anthony|  male|   1971-10-14|\n",
      "|  2|      102|        Ida Shipp|female|   1962-05-24|\n",
      "|  3|      103|     Joanna Moore|female|   2017-03-10|\n",
      "|  4|      104|   Lisandra Ortiz|female|   2020-08-05|\n",
      "|  5|      105|    David Simmons|  male|   1999-12-30|\n",
      "|  6|      106|    Edward Hudson|  male|   1983-05-09|\n",
      "|  7|      107|     Albert Jones|  male|   1990-09-13|\n",
      "|  8|      108| Leonard Cavender|  male|   1958-08-08|\n",
      "|  9|      109|   Everett Vadala|  male|   2005-05-24|\n",
      "| 10|      110| Freddie Claridge|  male|   2002-05-07|\n",
      "| 11|      111|Annabelle Rosseau|female|   1989-07-13|\n",
      "| 12|      112|    Eulah Emanuel|female|   1976-01-19|\n",
      "| 13|      113|       Shaun Love|  male|   1970-05-26|\n",
      "| 14|      114|Alejandro Brennan|  male|   1980-12-22|\n",
      "| 15|      115|Robert Mcreynolds|  male|   1973-12-27|\n",
      "| 16|      116|   Carla Spickard|female|   1985-06-13|\n",
      "| 17|      117|Florence Eberhart|female|   2024-06-01|\n",
      "| 18|      118|     Tina Gaskins|female|   1966-12-05|\n",
      "| 19|      119| Florence Mulhern|female|   1959-05-31|\n",
      "+---+---------+-----------------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_people.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- person_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- date of birth: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_people.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_people.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', 'person_id', 'name', 'sex', 'date of birth']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_people.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+-------------+\n",
      "|            name|   sex|date of birth|\n",
      "+----------------+------+-------------+\n",
      "|  Penelope Lewis|female|   1990-08-31|\n",
      "|   David Anthony|  male|   1971-10-14|\n",
      "|       Ida Shipp|female|   1962-05-24|\n",
      "|    Joanna Moore|female|   2017-03-10|\n",
      "|  Lisandra Ortiz|female|   2020-08-05|\n",
      "|   David Simmons|  male|   1999-12-30|\n",
      "|   Edward Hudson|  male|   1983-05-09|\n",
      "|    Albert Jones|  male|   1990-09-13|\n",
      "|Leonard Cavender|  male|   1958-08-08|\n",
      "|  Everett Vadala|  male|   2005-05-24|\n",
      "+----------------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_people_sub = df_people.select(\"name\", \"sex\", \"date of birth\")\n",
    "df_people_sub.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below Dropping Duplicates 100000\n",
      "After Dropping Duplicates 100000\n"
     ]
    }
   ],
   "source": [
    "df_people_nodups = df_people.dropDuplicates()\n",
    "print(\"Below Dropping Duplicates\", df_people.count())\n",
    "print(\"After Dropping Duplicates\", df_people_nodups.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people_females = df_people.filter(df_people.sex == \"female\")\n",
    "df_people_males = df_people.filter(df_people.sex == \"male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49014"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_people_females.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49066"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_people_males.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   sex|count|\n",
      "+------+-----+\n",
      "|  null| 1920|\n",
      "|female|49014|\n",
      "|  male|49066|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_people_sex = df_people.groupBy(\"sex\")\n",
    "df_people_sex.count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------------+------+-------------+\n",
      "|  _c0|person_id|           name|   sex|date of birth|\n",
      "+-----+---------+---------------+------+-------------+\n",
      "|57359|    57459|   Sharon Perez|female|   1899-08-28|\n",
      "|62233|    62333|Martina Morison|female|   1901-04-21|\n",
      "|96318|    96418|   Lisa Garrett|female|   1901-05-09|\n",
      "|39703|    39803|    Naomi Davis|female|   1902-04-25|\n",
      "|64563|    64663|  Brenda French|female|   1902-07-27|\n",
      "|32026|    32126|   Tyler Walton|  male|   1903-07-14|\n",
      "|38717|    38817|  Daniel Naiman|  male|   1903-11-07|\n",
      "|  361|      461| Christy Dawson|female|   1904-01-11|\n",
      "|42760|    42860|   John Merritt|  male|   1906-11-04|\n",
      "|12763|    12863|   Roger Watkin|  male|   1907-12-08|\n",
      "| 6477|     6577|   Marie Givens|female|   1908-02-15|\n",
      "|52436|    52536|Maribel Donahoe|female|   1908-11-27|\n",
      "|   85|      185|    Paula Evans|female|   1909-02-10|\n",
      "|85976|    86076|     Tim Makris|  male|   1909-07-11|\n",
      "|36967|    37067|   Joyce Jacoby|female|   1909-09-13|\n",
      "|32878|    32978|     Tina Foret|female|   1909-11-20|\n",
      "|47375|    47475|    Jeremy Jost|  male|   1910-04-14|\n",
      "|35776|    35876|  Fredrick Nass|  male|   1911-01-12|\n",
      "|34961|    35061|     Shaun King|  male|   1911-03-27|\n",
      "|52677|    52777|Mitchell Martin|  male|   1911-07-06|\n",
      "+-----+---------+---------------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_people.orderBy(\"date of birth\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------------+------+----------+\n",
      "|_c0|person_id|             name|   sex|       DOB|\n",
      "+---+---------+-----------------+------+----------+\n",
      "|  0|      100|   Penelope Lewis|female|1990-08-31|\n",
      "|  1|      101|    David Anthony|  male|1971-10-14|\n",
      "|  2|      102|        Ida Shipp|female|1962-05-24|\n",
      "|  3|      103|     Joanna Moore|female|2017-03-10|\n",
      "|  4|      104|   Lisandra Ortiz|female|2020-08-05|\n",
      "|  5|      105|    David Simmons|  male|1999-12-30|\n",
      "|  6|      106|    Edward Hudson|  male|1983-05-09|\n",
      "|  7|      107|     Albert Jones|  male|1990-09-13|\n",
      "|  8|      108| Leonard Cavender|  male|1958-08-08|\n",
      "|  9|      109|   Everett Vadala|  male|2005-05-24|\n",
      "| 10|      110| Freddie Claridge|  male|2002-05-07|\n",
      "| 11|      111|Annabelle Rosseau|female|1989-07-13|\n",
      "| 12|      112|    Eulah Emanuel|female|1976-01-19|\n",
      "| 13|      113|       Shaun Love|  male|1970-05-26|\n",
      "| 14|      114|Alejandro Brennan|  male|1980-12-22|\n",
      "| 15|      115|Robert Mcreynolds|  male|1973-12-27|\n",
      "| 16|      116|   Carla Spickard|female|1985-06-13|\n",
      "| 17|      117|Florence Eberhart|female|2024-06-01|\n",
      "| 18|      118|     Tina Gaskins|female|1966-12-05|\n",
      "| 19|      119| Florence Mulhern|female|1959-05-31|\n",
      "+---+---------+-----------------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_people = df_people.withColumnRenamed(\"date of birth\", \"DOB\")\n",
    "df_people.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Using Spark SQL module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|             name|       DOB|\n",
      "+-----------------+----------+\n",
      "|     Tyler Walton|1903-07-14|\n",
      "|    Daniel Naiman|1903-11-07|\n",
      "|     John Merritt|1906-11-04|\n",
      "|     Roger Watkin|1907-12-08|\n",
      "|       Tim Makris|1909-07-11|\n",
      "|      Jeremy Jost|1910-04-14|\n",
      "|    Fredrick Nass|1911-01-12|\n",
      "|       Shaun King|1911-03-27|\n",
      "|  Mitchell Martin|1911-07-06|\n",
      "|     Daniel Rutan|1911-08-09|\n",
      "|Rigoberto Russell|1912-04-10|\n",
      "|  John Vanderpool|1912-07-25|\n",
      "|      Marc Maione|1912-09-09|\n",
      "|   Charles Rustin|1914-01-22|\n",
      "|  Tyrone Clarkson|1915-03-02|\n",
      "|     Andy Cameron|1915-12-03|\n",
      "|  Anthony Gardner|1916-03-12|\n",
      "|   Wayne Thatcher|1916-05-24|\n",
      "|    Todd Hilliard|1916-08-16|\n",
      "|    Joshua Maddox|1916-10-06|\n",
      "+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_people.createOrReplaceTempView(\"people\")\n",
    "query = \"select name, DOB from people where sex='male' order by DOB\"\n",
    "df_people_names_dob = spark.sql(query)\n",
    "df_people_names_dob.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Create RDD from External File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterRDD = sc.textFile(\"5000_points.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterRDD = sc.textFile(\"5000_points.txt\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['664159\\t550946',\n",
       " '665845\\t557965',\n",
       " '597173\\t575538',\n",
       " '618600\\t551446',\n",
       " '635690\\t608046']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_split = clusterRDD.map(lambda x: x.split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['664159', '550946'],\n",
       " ['665845', '557965'],\n",
       " ['597173', '575538'],\n",
       " ['618600', '551446'],\n",
       " ['635690', '608046']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_split.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_split_int = rdd_split.map(lambda x: [int(x[0]), int(x[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[664159, 550946],\n",
       " [665845, 557965],\n",
       " [597173, 575538],\n",
       " [618600, 551446],\n",
       " [635690, 608046]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_split_int.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
